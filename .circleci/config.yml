# Python CircleCI 2.0 configuration file
#
# Check https://circleci.com/docs/2.0/language-python/ for more details
# 
#


version: 2.1
orbs:
  aws-s3: circleci/aws-s3@1.0.11
jobs:
  build:
    docker:
      - image: 'circleci/python:2.7'
    steps:
      - checkout
      - run: mkdir bucket && echo "lorum ipsum" > bucket/build_asset.txt
      - run: echo $AWS_ACCESS_KEY_ID
      - aws-s3/sync:
          from: bucket
          to: 's3://kde-metrics'
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          aws-region: AWS_REGION
          arguments: |
            --acl public-read \
            --cache-control "max-age=86400"
          overwrite: true
      # - aws-s3/copy:
      #     from: bucket/build_asset.txt
      #     to: 's3://kde-metrics'
      #     arguments: '--dryrun'

      - run: echo "test two"

# version: 2.1
# orbs:
#   aws-cli: circleci/aws-cli@0.1.16
# jobs:
#   build:
#     docker:
#       # specify the version you desire here
#       # use `-browsers` prefix for selenium tests, e.g. `3.6.1-browsers`
#       - image: circleci/python:3.6.1

#       # Specify service dependencies here if necessary
#       # CircleCI maintains a library of pre-built images
#       # documented at https://circleci.com/docs/2.0/circleci-images/
#       # - image: circleci/postgres:9.4

#     working_directory: ~/repo

#     steps:
#       - checkout
#   aws-cli-example:
#     executor: aws-cli/default
#     steps:
#       - checkout
#       - aws-cli/setup:
#           profile-name: example
#       - run: echo "Run your code here"

# workflows:
#   version: 2
#   aws-cli:
#     jobs:
#       - aws-cli-example:
#           context: aws

    # steps:
    #   - checkout
    #   - run: sudo pip install awscli
    #   #- run: mkdir bucket && echo "lorum ipsum" > bucket/build_asset.txt
    #   - run: mkdir bucket && echo "lorum ipsum" > bucket/build_asset.txt && sudo pip install awscli
    #   - run:
    #       name: Configure AWS Access Key ID
    #       command: >
            
    #         aws configure set aws_access_key_id \

    #         $AWS_ACCESS_KEY_ID \

    #         echo "Print the value for $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY"
    #   - aws-s3/sync:
    #       from: bucket
    #       to: 's3://kde-metrics/'
    #       aws-access-key-id: AWS_ACCESS_KEY_ID
    #       aws-secret-access-key: AWS_SECRET_ACCESS_KEY
    #       aws-region: AWS_REGION
    #       arguments: |
    #         --acl public-read \
    #         --cache-control "max-age=86400"
    #       overwrite: true
    #   - aws-s3/copy:
    #       from: bucket/build_asset.txt
    #       to: 's3://kde-metrics'
    #       arguments: '--dryrun'

    #   # Download and cache dependencies
    #   - restore_cache:
    #       keys:
    #         - v1-dependencies-{{ checksum "requirements.txt" }}
    #         # fallback to using the latest cache if no exact match is found
    #         - v1-dependencies-

      # this is where the docker setup scripts will need to be run
#      - run:
#          name: install dependencies
#          command: |
#            docker-compose up -d --build
#            . venv/bin/activate
#            pip install -r requirements.txt

#      - save_cache:
#          paths:
#            - ./venv
#          key: v1-dependencies-{{ checksum "requirements.txt" }}

      # run tests!
      # this example uses Django's built-in test-runner
      # other common Python testing frameworks include pytest and nose
      # https://pytest.org
      # https://nose.readthedocs.io
#      - run:
#          name: run tests
#          command: |
#            . venv/bin/activate
#            python manage.py test
#
#      - store_artifacts:
#          path: test-reports
#          destination: test-reports
